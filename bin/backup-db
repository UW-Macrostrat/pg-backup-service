#!/bin/bash

source defs.bash

if [ -z $DB_NAME ] && [ -z $PGDATABASE ] ; then
  echo "Neither DB_NAME or PGDATABASE is set!"
  exit 1
fi

if [ -z $DB_NAME ]; then
  echo "DB_NAME is not set, falling back to PGDATABASE"
  if [[ $PGDATABASE =~ "," ]]; then
    echo "PGDATABASE cannot be set to a comma-delimited list!"
    exit 1
  fi
  export DB_NAME=$PGDATABASE
fi

check-vars "for backup" DB_NAME || exit 1

backup_dir=""
if [ -n "$DB_BACKUP_PREFIX" ]; then
  backup_dir="$DB_BACKUP_PREFIX/"
fi

# Set defaults for standard PostgreSQL environment variables:
# https://www.postgresql.org/docs/9.1/libpq-envars.html
export PGUSER=${PGUSER:-postgres}
export PGHOST=${PGHOST:-localhost}
export PGPORT=${PGPORT:-5432}

while ! pg_isready ; do
  echo "Waiting for PostgreSQL server to be ready..."
  sleep 1
done

databases=$(echo $DB_NAME | tr "," "\n")
for dbname in $databases ; do
  # Set postgres environment variables
  export PGDATABASE=$dbname
  dumpfile=""
  did_something=false
  # We mount local DB_BACKUP_DIR as 
  if check-vars "local backup" DB_BACKUP_DIR ; then
    # Back up to the local directory
    # Dump the database. Files always change, unfortunately.
    # Add an extra variable to be more specific about the mounted directory 
    export DB_BACKUP_VOLUME=${DB_BACKUP_VOLUME:-"$DB_BACKUP_DIR"}

    dump_dir="$DB_BACKUP_VOLUME/$backup_dir"
    dumpfile="$(run-backup $dbname $dump_dir)"
    [ ! -f "$dumpfile" ] && exit 1
    did_something=true
  fi

  # Rest of the script is for backing up to a server...

  if check-vars "cloud backup" \
    S3_ENDPOINT \
    S3_ACCESS_KEY \
    S3_SECRET_KEY \
    S3_BACKUP_BUCKET ; then

    echo "Running cloud backup"

    remote=remote:$S3_BACKUP_BUCKET
    list=/tmp/bucket-list


    remote_dump=$remote/$backup_dir

    find-remote-backups $dbname > $list

    nfiles=$(cat $list | wc -l)

    echo "Existing backups:"
    cat $list
    echo ""

    oldest_file=$(cat $list | head -n 1)
    latest_file=$(cat $list | tail -n 1)


    # Dump the database if it hasn't already been dumped
    if [ ! -f "$dumpfile" ]; then
      dumpfile=$(run-backup $dbname /tmp)
    fi
    [ ! -f "$dumpfile" ] && exit 1

    echo "Uploading to $remote_dump"
    rclone copy $dumpfile $remote_dump

    # Prune oldest backup if there are many
    max_n=${DB_BACKUP_MAX_N:-10}
    if [ $nfiles -gt $max_n ]; then
      echo "More than $max_n backups available."
      echo "Pruning the oldest ($oldest_file)."
      remove-remote-backup $oldest_file
    fi

    rm -f $list
    rm -rf /tmp/*

    did_something=true
  fi
done

if [ "$did_something" = false ]; then
  echo "Insufficient information specified for local or S3 backup."
  exit 1
fi